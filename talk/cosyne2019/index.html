<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.3.0">
  <meta name="generator" content="Hugo 0.53" />
  <meta name="author" content="Francisco Jose Luongo">

  
  
  
  
    
  
  <meta name="description" content="Studies of the rodent visual system have exploded in recent years, revealing tuning to elementary image features similar to primates. How are these features further transformed? In the primate, researchers have argued that a key transformation is ?figure-ground segmentation.? Behaviorally, humans can delineate figures from backgrounds using only kinetic borders independent of low-level texture cues. Neurally, long-latency enhancement of responses in early visual areas to regions within figure compared to background has been reported. Do mice also show behavioral and neural signatures of figure-ground segmentation? We trained mice on a figure-ground segmentation task where figures were defined by gratings and naturalistic textures, moving counterphase to the background. Unlike primates, mice were incapable of figure-ground segmentation using kinetic borders alone. While mice could report the location of gratings, they were at chance for figures defined by naturalistic textures. Remarkably, mice could learn to localize naturalistic texture-defined figures after many weeks of training, but when tested on new textures, were unable to generalize. This suggests a strategy of memorizing a lookup table of noise patterns, a cognitively impressive feat. We also recorded visual responses to the same stimuli in V1, RL, and LM using both 2-photon imaging and electrophysiology. Neural responses were consistent with the behavior, revealing robust position decoding from neural populations for gratings but not naturalistic textures. Lastly, we simulated neural responses using a model of V1 incorporating orientation-dependent suppression, and a deep network, VGG16. While the former model failed to reproduce the neural results, the latter model was successful. Interestingly, the best model for mouse V1 neural data came from mid to late layers. Taken together, these findings reveal a fundamental difference between primate and mouse mechanisms for object segmentation, showing that orientation contrast is critical for object perception in mice, unlike in primates.">

  
  <link rel="alternate" hreflang="en-us" href="/talk/cosyne2019/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Francisco Jose Luongo">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Francisco Jose Luongo">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/talk/cosyne2019/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Francisco Jose Luongo">
  <meta property="og:url" content="/talk/cosyne2019/">
  <meta property="og:title" content="A fundamental difference between rodent and primate object vision | Francisco Jose Luongo">
  <meta property="og:description" content="Studies of the rodent visual system have exploded in recent years, revealing tuning to elementary image features similar to primates. How are these features further transformed? In the primate, researchers have argued that a key transformation is ?figure-ground segmentation.? Behaviorally, humans can delineate figures from backgrounds using only kinetic borders independent of low-level texture cues. Neurally, long-latency enhancement of responses in early visual areas to regions within figure compared to background has been reported. Do mice also show behavioral and neural signatures of figure-ground segmentation? We trained mice on a figure-ground segmentation task where figures were defined by gratings and naturalistic textures, moving counterphase to the background. Unlike primates, mice were incapable of figure-ground segmentation using kinetic borders alone. While mice could report the location of gratings, they were at chance for figures defined by naturalistic textures. Remarkably, mice could learn to localize naturalistic texture-defined figures after many weeks of training, but when tested on new textures, were unable to generalize. This suggests a strategy of memorizing a lookup table of noise patterns, a cognitively impressive feat. We also recorded visual responses to the same stimuli in V1, RL, and LM using both 2-photon imaging and electrophysiology. Neural responses were consistent with the behavior, revealing robust position decoding from neural populations for gratings but not naturalistic textures. Lastly, we simulated neural responses using a model of V1 incorporating orientation-dependent suppression, and a deep network, VGG16. While the former model failed to reproduce the neural results, the latter model was successful. Interestingly, the best model for mouse V1 neural data came from mid to late layers. Taken together, these findings reveal a fundamental difference between primate and mouse mechanisms for object segmentation, showing that orientation contrast is critical for object perception in mice, unlike in primates."><meta property="og:image" content="/img/headers/bubbles-wide.jpg">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-03-01T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2019-03-01T00:00:00&#43;00:00">
  

  

  

  <title>A fundamental difference between rodent and primate object vision | Francisco Jose Luongo</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" class="dark">
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Francisco Jose Luongo</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/files/cv.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>

<div class="pub" itemscope itemtype="http://schema.org/Event">

  









<div class="article-header">
  
  
  <img src="/img/headers/bubbles-wide.jpg" class="article-banner" itemprop="image" alt="">
  

  <span class="article-header-caption">My caption ðŸ˜„</span>
</div>




  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">A fundamental difference between rodent and primate object vision</h1>

  

  
    

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">F. Luongo</span>
    </span>, 
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">L. Liu</span>
    </span>, 
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">D. Tsao</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2019-03-01 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2019-03-01 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Mar 1, 2019
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Francisco Jose Luongo">
  </span>

  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=A%20fundamental%20difference%20between%20rodent%20and%20primate%20object%20vision&amp;url=%2ftalk%2fcosyne2019%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2ftalk%2fcosyne2019%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2ftalk%2fcosyne2019%2f&amp;title=A%20fundamental%20difference%20between%20rodent%20and%20primate%20object%20vision"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2ftalk%2fcosyne2019%2f&amp;title=A%20fundamental%20difference%20between%20rodent%20and%20primate%20object%20vision"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=A%20fundamental%20difference%20between%20rodent%20and%20primate%20object%20vision&amp;body=%2ftalk%2fcosyne2019%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    














<div class="btn-links mb-3">
  
  







  










  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1" href="/pdf/my-paper-name.pdf" target="_blank" rel="noopener">
  Poster
</a>









</div>


  
</div>



  <div class="article-container">

    
      <h3>Abstract</h3>
      <p class="pub-abstract" itemprop="text">Studies of the rodent visual system have exploded in recent years, revealing tuning to elementary image features similar to primates. How are these features further transformed? In the primate, researchers have argued that a key transformation is ?figure-ground segmentation.? Behaviorally, humans can delineate figures from backgrounds using only kinetic borders independent of low-level texture cues. Neurally, long-latency enhancement of responses in early visual areas to regions within figure compared to background has been reported. Do mice also show behavioral and neural signatures of figure-ground segmentation? We trained mice on a figure-ground segmentation task where figures were defined by gratings and naturalistic textures, moving counterphase to the background. Unlike primates, mice were incapable of figure-ground segmentation using kinetic borders alone. While mice could report the location of gratings, they were at chance for figures defined by naturalistic textures. Remarkably, mice could learn to localize naturalistic texture-defined figures after many weeks of training, but when tested on new textures, were unable to generalize. This suggests a strategy of memorizing a lookup table of noise patterns, a cognitively impressive feat. We also recorded visual responses to the same stimuli in V1, RL, and LM using both 2-photon imaging and electrophysiology. Neural responses were consistent with the behavior, revealing robust position decoding from neural populations for gratings but not naturalistic textures. Lastly, we simulated neural responses using a model of V1 incorporating orientation-dependent suppression, and a deep network, VGG16. While the former model failed to reproduce the neural results, the latter model was successful. Interestingly, the best model for mouse V1 neural data came from mid to late layers. Taken together, these findings reveal a fundamental difference between primate and mouse mechanisms for object segmentation, showing that orientation contrast is critical for object perception in mice, unlike in primates.</p>
    

    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Date</div>
          <div class="col-12 col-md-9" itemprop="datePublished">
            
            Mar 1, 2019
            <div class="talk-time">
              
            </div>
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>

    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Event</div>
          <div class="col-12 col-md-9">
            
            
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>

    

    <div class="space-below"></div>

    <div class="article-style">
      
    </div>

    

    



  







  </div>
</div>



<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    <script src="/js/academic.min.07fbebbbf71b021c8836e1d7ecffa489.js"></script>

    

  </body>
</html>

